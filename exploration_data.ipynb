{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\yulia\\AppData\\Local\\Temp\\ipykernel_13000\\850320232.py:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  df = pd.read_csv('data\\Real_Estate_Sales_2001-2022_GL.csv')\n",
      "C:\\Users\\yulia\\AppData\\Local\\Temp\\ipykernel_13000\\850320232.py:2: DtypeWarning: Columns (8,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data\\Real_Estate_Sales_2001-2022_GL.csv')\n"
     ]
    }
   ],
   "source": [
    "# Loading Dataset for Sales in Conneticut to Pandas\n",
    "df = pd.read_csv('data\\Real_Estate_Sales_2001-2022_GL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial Number             0\n",
       "List Year                 0\n",
       "Date Recorded             2\n",
       "Town                      0\n",
       "Address                  51\n",
       "Assessed Value            0\n",
       "Sale Amount               0\n",
       "Sales Ratio               0\n",
       "Property Type        382446\n",
       "Residential Type     398389\n",
       "Non Use Code         784178\n",
       "Assessor Remarks     926401\n",
       "OPM remarks         1084598\n",
       "Location             799518\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping colums that won't be useful for modeling\n",
    "df_clean = df.drop(columns = ['Serial Number', 'OPM remarks', 'Assessor Remarks', 'Non Use Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping transactions with no sale amount\n",
    "df_clean = df_clean[df_clean['Sale Amount'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List Year</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Sale Amount</th>\n",
       "      <th>Sales Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.095819e+06</td>\n",
       "      <td>1.095819e+06</td>\n",
       "      <td>1.095819e+06</td>\n",
       "      <td>1.095819e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.011231e+03</td>\n",
       "      <td>2.819331e+05</td>\n",
       "      <td>4.059840e+05</td>\n",
       "      <td>9.619789e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.770525e+00</td>\n",
       "      <td>1.658927e+06</td>\n",
       "      <td>5.147712e+06</td>\n",
       "      <td>1.803151e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.001000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.005000e+03</td>\n",
       "      <td>8.915000e+04</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>4.785714e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.011000e+03</td>\n",
       "      <td>1.406300e+05</td>\n",
       "      <td>2.340000e+05</td>\n",
       "      <td>6.110000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>2.283400e+05</td>\n",
       "      <td>3.750000e+05</td>\n",
       "      <td>7.711000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.022000e+03</td>\n",
       "      <td>8.815100e+08</td>\n",
       "      <td>5.000000e+09</td>\n",
       "      <td>1.226420e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          List Year  Assessed Value   Sale Amount   Sales Ratio\n",
       "count  1.095819e+06    1.095819e+06  1.095819e+06  1.095819e+06\n",
       "mean   2.011231e+03    2.819331e+05  4.059840e+05  9.619789e+00\n",
       "std    6.770525e+00    1.658927e+06  5.147712e+06  1.803151e+03\n",
       "min    2.001000e+03    0.000000e+00  1.000000e+00  0.000000e+00\n",
       "25%    2.005000e+03    8.915000e+04  1.450000e+05  4.785714e-01\n",
       "50%    2.011000e+03    1.406300e+05  2.340000e+05  6.110000e-01\n",
       "75%    2.018000e+03    2.283400e+05  3.750000e+05  7.711000e-01\n",
       "max    2.022000e+03    8.815100e+08  5.000000e+09  1.226420e+06"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing current state of database\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List Year                0\n",
       "Date Recorded            0\n",
       "Town                     0\n",
       "Address                 24\n",
       "Assessed Value           0\n",
       "Sale Amount              0\n",
       "Sales Ratio              0\n",
       "Property Type       380748\n",
       "Residential Type    396691\n",
       "Location            798031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values again\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Residential' 'Commercial' 'Vacant Land' 'Public Utility' 'Apartments'\n",
      " nan 'Industrial' 'Condo' 'Two Family' 'Single Family' 'Three Family'\n",
      " 'Four Family']\n"
     ]
    }
   ],
   "source": [
    "# Check the unique property types in the dataset. \n",
    "unique_values_property_type = df_clean['Property Type'].unique()\n",
    "print(unique_values_property_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each sales ratio appears in the dataset. How many properties sold for exactly the assessed price?\n",
    "price_to_sell = df_clean['Sales Ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yulia\\AppData\\Local\\Temp\\ipykernel_13000\\1692148295.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean['Property Type'].fillna('unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Property Type' values with 'unknown'\n",
    "df_clean['Property Type'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List Year                0\n",
       "Date Recorded            0\n",
       "Town                     0\n",
       "Address                 24\n",
       "Assessed Value           0\n",
       "Sale Amount              0\n",
       "Sales Ratio              0\n",
       "Property Type            0\n",
       "Residential Type    396691\n",
       "Location            798031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yulia\\AppData\\Local\\Temp\\ipykernel_13000\\25978290.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean['Residential Type'].fillna('non-residential', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'Residential Type' values with 'non-residential'\n",
    "df_clean['Residential Type'].fillna('non-residential', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List Year                0\n",
       "Date Recorded            0\n",
       "Town                     0\n",
       "Address                 24\n",
       "Assessed Value           0\n",
       "Sale Amount              0\n",
       "Sales Ratio              0\n",
       "Property Type            0\n",
       "Residential Type         0\n",
       "Location            798031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Address' values with 'unknown'\n",
    "df_clean.fillna({'Address': 'unknown'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List Year                0\n",
       "Date Recorded            0\n",
       "Town                     0\n",
       "Address                  0\n",
       "Assessed Value           0\n",
       "Sale Amount              0\n",
       "Sales Ratio              0\n",
       "Property Type            0\n",
       "Residential Type         0\n",
       "Location            798031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date Recorded' to datetime format to make use of month value\n",
    "df_clean['Date Recorded'] = pd.to_datetime(df_clean['Date Recorded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to categorize sales into seasons based on the month\n",
    "def season_of_sale(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "    \n",
    "# Apply the function to create a new 'season_sold' column\n",
    "df_clean['season_sold'] = df_clean['Date Recorded'].dt.month.apply(season_of_sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['List Year', 'Date Recorded', 'Town', 'Address', 'Assessed Value',\n",
      "       'Sale Amount', 'Sales Ratio', 'Property Type', 'Residential Type',\n",
      "       'Location', 'season_sold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print column names to verify the new feature was added\n",
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season_sold\n",
      "Summer    335963\n",
      "Fall      278699\n",
      "Spring    259308\n",
      "Winter    221849\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of sales in each season. This is definitely useful, more properties are sold in summer\n",
    "season_count = df_clean['season_sold'].value_counts()\n",
    "print(season_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        List Year Date Recorded        Town                      Address  \\\n",
      "59788        2020    2021-08-19  Willington             456 TOLLAND TPKE   \n",
      "799678       2016    2016-12-06    Stamford             115 TOWNE STREET   \n",
      "801991       2016    2016-12-06    Stamford         200 HENRY STREET # 3   \n",
      "825265       2016    2016-12-06    Stamford         200 HENRY STREET # 4   \n",
      "835261       2016    2016-12-06    Stamford             120 TOWNE STREET   \n",
      "...           ...           ...         ...                          ...   \n",
      "30352        2020    2021-01-15    Stamford       93 GLENBROOK ROAD #105   \n",
      "32960        2020    2021-01-15    Stamford       93 GLENBROOK ROAD #205   \n",
      "33538        2020    2021-01-15    Stamford       93 GLENBROOK ROAD #101   \n",
      "34802        2020    2021-01-15    Stamford       93 GLENBROOK ROAD #201   \n",
      "38016        2020    2021-01-15    Stamford  93 GLENBROOK ROAD GARAGE #2   \n",
      "\n",
      "        Assessed Value   Sale Amount  Sales Ratio Property Type  \\\n",
      "59788        2238530.0  5.000000e+09     0.000448    Apartments   \n",
      "799678      50820110.0  3.955000e+08     0.128496       unknown   \n",
      "801991      10829090.0  3.955000e+08     0.027381       unknown   \n",
      "825265      10935790.0  3.955000e+08     0.027651       unknown   \n",
      "835261      56144510.0  3.955000e+08     0.141958       unknown   \n",
      "...                ...           ...          ...           ...   \n",
      "30352         111750.0  7.200000e+07     0.001500   Residential   \n",
      "32960         115550.0  7.200000e+07     0.001600   Residential   \n",
      "33538         134130.0  7.200000e+07     0.001800   Residential   \n",
      "34802         124390.0  7.200000e+07     0.001700   Residential   \n",
      "38016           6970.0  7.200000e+07     0.000000   Residential   \n",
      "\n",
      "       Residential Type                    Location season_sold  \n",
      "59788   non-residential                         NaN      Summer  \n",
      "799678  non-residential                         NaN      Winter  \n",
      "801991  non-residential   POINT (-73.53597 41.0442)      Winter  \n",
      "825265  non-residential                         NaN      Winter  \n",
      "835261  non-residential  POINT (-73.53568 41.04536)      Winter  \n",
      "...                 ...                         ...         ...  \n",
      "30352             Condo  POINT (-73.52826 41.05864)      Winter  \n",
      "32960             Condo                         NaN      Winter  \n",
      "33538             Condo                         NaN      Winter  \n",
      "34802             Condo  POINT (-73.52826 41.05864)      Winter  \n",
      "38016             Condo                         NaN      Winter  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking top sales.\n",
    "top_100_sales = df_clean.nlargest(100, 'Sale Amount')\n",
    "print(top_100_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "5000000000.0\n"
     ]
    }
   ],
   "source": [
    "# When seeing described database, some high sales were alarming. Checking highest and lowest.\n",
    "min_saleprice = df_clean['Sale Amount'].min()\n",
    "max_saleprice = df_clean['Sale Amount'].max()\n",
    "print(min_saleprice)\n",
    "print(max_saleprice)\n",
    "# Definitely concerning. Queuing iup to resolve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        List Year Date Recorded        Town            Address  \\\n",
      "131300       2002    2002-11-12    Hartford      57 GILLETT ST   \n",
      "194436       2003    2003-12-30    Brooklyn        HARTFORD RD   \n",
      "205779       2003    2004-07-22     Bristol    66 EMMETT ST 12   \n",
      "214135       2003    2004-03-19    Thompson  0 & 12 JOHNSON ST   \n",
      "217960       2003    2004-03-19    Thompson  0 & 12 JOHNSON ST   \n",
      "...           ...           ...         ...                ...   \n",
      "869474       2017    2017-11-14     Norwalk      LEDGEBROOK DR   \n",
      "67068        2002    2003-08-11      Oxford   MAPLE TREE HL RD   \n",
      "432254       2006    2007-03-26    Coventry      BEECHWOOD TRL   \n",
      "243195       2004    2005-06-21  East Haven       50 VENICE PL   \n",
      "310429       2004    2005-09-12      Monroe    115 BOOTH HL ST   \n",
      "\n",
      "        Assessed Value  Sale Amount    Sales Ratio Property Type  \\\n",
      "131300        165060.0          1.0  165060.000000       unknown   \n",
      "194436           490.0          1.0     490.000000       unknown   \n",
      "205779          9520.0          1.0    9520.000000       unknown   \n",
      "214135         83000.0          1.0   83000.000000       unknown   \n",
      "217960         83000.0          1.0   83000.000000       unknown   \n",
      "...                ...          ...            ...           ...   \n",
      "869474          9400.0        500.0      18.800000         Condo   \n",
      "67068            530.0        530.0       1.000000       unknown   \n",
      "432254           800.0        570.0       1.403509       unknown   \n",
      "243195           180.0        573.0       0.314136       unknown   \n",
      "310429           140.0        600.0       0.233333       unknown   \n",
      "\n",
      "       Residential Type                    Location season_sold  \n",
      "131300  non-residential                         NaN        Fall  \n",
      "194436  non-residential                         NaN      Winter  \n",
      "205779  non-residential  POINT (-72.91363 41.66961)      Summer  \n",
      "214135  non-residential                         NaN      Spring  \n",
      "217960  non-residential                         NaN      Spring  \n",
      "...                 ...                         ...         ...  \n",
      "869474            Condo                         NaN        Fall  \n",
      "67068   non-residential                         NaN      Summer  \n",
      "432254  non-residential                         NaN      Spring  \n",
      "243195  non-residential                         NaN      Summer  \n",
      "310429  non-residential                         NaN        Fall  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Show the lowest 100 sales by 'Sale Amount'\n",
    "lowest_100_sales = df_clean.nsmallest(100, 'Sale Amount')\n",
    "print(lowest_100_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absurdly low: 10400.0\n",
      "Absurdly high: 13650000.0\n"
     ]
    }
   ],
   "source": [
    "# Define lower and upper bounds for what is considered absurdly low or high sales\n",
    "low_absurd = 0.01\n",
    "high_absurd = 0.999\n",
    "\n",
    "# Calculate the lower and upper bounds based on quantiles of the 'Sale Amount' column\n",
    "lower_bound = df_clean['Sale Amount'].quantile(low_absurd)\n",
    "upper_bound = df_clean['Sale Amount'].quantile(high_absurd)\n",
    "\n",
    "# Print the absurdly low and high values\n",
    "print(f\"Absurdly low: {lower_bound}\")\n",
    "print(f\"Absurdly high: {upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1083833, 11)\n",
      "count    1.083833e+06\n",
      "mean     3.697899e+05\n",
      "std      6.224099e+05\n",
      "min      1.040000e+04\n",
      "25%      1.480000e+05\n",
      "50%      2.350000e+05\n",
      "75%      3.790000e+05\n",
      "max      1.365000e+07\n",
      "Name: Sale Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to remove absurdly low or high sales\n",
    "df_clean_filtered = df_clean[(df_clean['Sale Amount'] >= lower_bound) & (df_clean['Sale Amount'] <= upper_bound)]\n",
    "\n",
    "# Check how sale amounts look after filtering\n",
    "print(df_clean_filtered.shape)\n",
    "print(df_clean_filtered['Sale Amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['Property Type', 'Town', 'Property Type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling to the numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[num_features] = scaler.fit_transform(df_encoded[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical features for scaling and modeling. Not too many numerical features left but we work with what we have\n",
    "cat_features = df_encoded.columns[df_encoded.columns.str.startswith('Property Type_') | df_encoded.columns.str.startswith('Residential Type_') | df_encoded.columns.str.startswith('season_sold_')].tolist()\n",
    "num_features = ['Assessed Value', 'Sales Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "features = cat_features + num_features\n",
    "target = 'Sale Amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X = df_encoded[features]\n",
    "y = df_encoded[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple regression models to try\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\REAL-ESTATE-EDA-AND-MODEL\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 1660009.4344344118, R² = 0.1653231610968654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\REAL-ESTATE-EDA-AND-MODEL\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: RMSE = 716333.1612701032, R² = 0.8445726784619175\n",
      "Gradient Boosting: RMSE = 637529.4597925631, R² = 0.8768887428738651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\REAL-ESTATE-EDA-AND-MODEL\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model, train it, and evaluate its performance\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance with RMSE and R2 score\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "    r2 = r2_score(y_test, y_pred)  \n",
    "    \n",
    "    # Print the model's name and its performance\n",
    "    print(f\"{name}: RMSE = {rmse}, R² = {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE scores: [11956275.69652412  1044499.55382542  1024126.14550588   482869.28329701\n",
      "   626053.81351854]\n",
      "Mean CV RMSE: 3026764.8985341927\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation on the Random Forest model\n",
    "cv_scores = cross_val_score(RandomForestRegressor(random_state=42), X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert the negative MSE to RMSE\n",
    "cv_rmse = np.sqrt(-cv_scores)\n",
    "\n",
    "# Print the cross-validation RMSE scores and their average\n",
    "print(f\"Cross-Validation RMSE scores: {cv_rmse}\")\n",
    "print(f\"Mean CV RMSE: {np.mean(cv_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
